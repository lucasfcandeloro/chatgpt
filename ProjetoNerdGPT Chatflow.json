{
  "nodes": [
    {
      "id": "groqChat_0",
      "position": {
        "x": -412.64018427824334,
        "y": -291.6129297585295
      },
      "type": "customNode",
      "data": {
        "id": "groqChat_0",
        "label": "GroqChat",
        "version": 3,
        "name": "groqChat",
        "type": "GroqChat",
        "baseClasses": [
          "GroqChat",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Groq API with LPU Inference Engine",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "groqApi"
            ],
            "optional": true,
            "id": "groqChat_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "placeholder": "llama3-70b-8192",
            "id": "groqChat_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "groqChat_0-input-temperature-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "groqChat_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "llama3-70b-8192",
          "temperature": 0.9
        },
        "outputAnchors": [
          {
            "id": "groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "groqChat",
            "label": "GroqChat",
            "description": "Wrapper around Groq API with LPU Inference Engine",
            "type": "GroqChat | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 521,
      "selected": false,
      "positionAbsolute": {
        "x": -412.64018427824334,
        "y": -291.6129297585295
      },
      "dragging": false
    },
    {
      "id": "conversationChain_0",
      "position": {
        "x": 311.31225656707954,
        "y": -136.2897432259886
      },
      "type": "customNode",
      "data": {
        "id": "conversationChain_0",
        "label": "Conversation Chain",
        "version": 3,
        "name": "conversationChain",
        "type": "ConversationChain",
        "baseClasses": [
          "ConversationChain",
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chat models specific conversational chain with memory",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "description": "If Chat Prompt Template is provided, this will be ignored",
            "additionalParams": true,
            "optional": true,
            "default": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
            "placeholder": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
            "id": "conversationChain_0-input-systemMessagePrompt-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationChain_0-input-model-BaseChatModel"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "id": "conversationChain_0-input-memory-BaseMemory"
          },
          {
            "label": "Chat Prompt Template",
            "name": "chatPromptTemplate",
            "type": "ChatPromptTemplate",
            "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable",
            "optional": true,
            "id": "conversationChain_0-input-chatPromptTemplate-ChatPromptTemplate"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationChain_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{groqChat_0.data.instance}}",
          "memory": "{{bufferMemory_0.data.instance}}",
          "chatPromptTemplate": "",
          "inputModeration": "",
          "systemMessagePrompt": "\n# Você é um agente de inteligência artificial chamado NerdGPT, especializado em ensino de matemática para alunos do ensino fundamental e infantil. Seu principal objetivo é ajudar os alunos a desenvolverem seu raciocínio matemático de forma autônoma e confiante. Em vez de fornecer respostas diretas, você deve orientá-los através de perguntas estratégicas e sugestões que estimulem a reflexão e a compreensão dos conceitos matemáticos. Seu papel é criar um ambiente de aprendizado onde os alunos se sintam motivados a explorar, experimentar e encontrar soluções por conta própria, promovendo um desenvolvimento sólido de suas habilidades matemáticas e fortalecendo sua capacidade de resolver problemas. Use e abuse de emojis, hashtags, markdown, listas enumeradas e utilize técnicas neurolinguísticas e neuropedagogia.\n\n## O que você faz?\nVocê faz todo o desenvolvimento e contextualização do conteúdo para gerar uma resposta. \nVocê usa respostas profundas e bem detalhadas.\n\n## O que você não faz?\nVocê não responde de forma rasa.\nVocê não é prolixo.\nVocê não da respostas sem revisar 10 vezes.\n\n## Comportamento e Respostas:\n\n### Recepção e Acolhimento:\n\nCumprimente o aluno de maneira amigável e encorajadora.\nDemonstre entusiasmo em ajudá-lo a aprender matemática.\nEntendimento da Dúvida:\n\nPergunte ao aluno qual é a sua dúvida específica.\n\n### Orientação e Raciocínio:\n\nEm vez de dar a resposta direta, faça perguntas que levem o aluno a pensar sobre os conceitos envolvidos.\nUse exemplos e analogias simples para ajudar na compreensão.\nIncentive o aluno a explicar seu raciocínio e a identificar onde ele pode ter cometido um erro.\n\n### Feedback Positivo:\n\nElogie os esforços do aluno, independentemente da precisão das respostas.\nEncoraje o aluno a continuar tentando e a não desistir.\nEncerramento:\n\nResuma os pontos principais discutidos durante a interação.\nDeseje boa sorte ao aluno em seus estudos e encoraje-o a voltar sempre que tiver dúvidas.\n\n### Exemplos de Interação:\n\nAluno: Estou com dificuldade em entender como somar frações com denominadores diferentes.\n\nProfessor de IA:\n\"Entendi, somar frações com denominadores diferentes pode ser um desafio no começo, mas vamos trabalhar juntos nisso. Primeiro, você pode me dizer o que já sabe sobre frações e o que você já tentou fazer para somá-las?\"\n\nAluno: Eu sei que temos que encontrar um denominador comum, mas não sei como fazer isso.\n\nProfessor de IA:\n\"Ótimo, você está no caminho certo! Vamos pensar sobre como encontrar um denominador comum. Você lembra o que é um múltiplo comum entre dois números? Vamos usar as frações 1/4 e 1/6 como exemplo. Quais são os múltiplos de 4 e 6?\"\n\n"
        },
        "outputAnchors": [
          {
            "id": "conversationChain_0-output-conversationChain-ConversationChain|LLMChain|BaseChain|Runnable",
            "name": "conversationChain",
            "label": "ConversationChain",
            "description": "Chat models specific conversational chain with memory",
            "type": "ConversationChain | LLMChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 435,
      "selected": false,
      "positionAbsolute": {
        "x": 311.31225656707954,
        "y": -136.2897432259886
      },
      "dragging": false
    },
    {
      "id": "bufferMemory_0",
      "position": {
        "x": -82.08076453711085,
        "y": -269.08948598396387
      },
      "type": "customNode",
      "data": {
        "id": "bufferMemory_0",
        "label": "Buffer Memory",
        "version": 2,
        "name": "bufferMemory",
        "type": "BufferMemory",
        "baseClasses": [
          "BufferMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Retrieve chat messages stored in database",
        "inputParams": [
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "additionalParams": true,
            "optional": true,
            "id": "bufferMemory_0-input-sessionId-string"
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "bufferMemory_0-input-memoryKey-string"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "outputAnchors": [
          {
            "id": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "name": "bufferMemory",
            "label": "BufferMemory",
            "description": "Retrieve chat messages stored in database",
            "type": "BufferMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 253,
      "selected": false,
      "positionAbsolute": {
        "x": -82.08076453711085,
        "y": -269.08948598396387
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "groqChat_0",
      "sourceHandle": "groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationChain_0",
      "targetHandle": "conversationChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "groqChat_0-groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable-conversationChain_0-conversationChain_0-input-model-BaseChatModel"
    },
    {
      "source": "bufferMemory_0",
      "sourceHandle": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
      "target": "conversationChain_0",
      "targetHandle": "conversationChain_0-input-memory-BaseMemory",
      "type": "buttonedge",
      "id": "bufferMemory_0-bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory-conversationChain_0-conversationChain_0-input-memory-BaseMemory"
    }
  ]
}